{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLg/FiDfva752YoCT6TU3Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santoshyadav1983-ai/2025AA05910_ML_assignment2/blob/main/2025AA05910_ML_assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Models Implementation\n",
        "\n",
        "**Dataset:** Demographics.csv (Adult Income Dataset)\n",
        "\n",
        "**Objective:** Implement and compare 6 classification models to predict income levels (<=50K or >50K)\n",
        "\n",
        "## Models Implemented:\n",
        "1. Logistic Regression\n",
        "2. Decision Tree Classifier\n",
        "3. K-Nearest Neighbors Classifier\n",
        "4. Naive Bayes Classifier (Gaussian)\n",
        "5. Ensemble Model - Random Forest\n",
        "6. Ensemble Model - XGBoost"
      ],
      "metadata": {
        "id": "tzYZbiWrsHWO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import Required Libraries"
      ],
      "metadata": {
        "id": "R8UHccM1sMpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score, classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS0xDlTRsN5f",
        "outputId": "665a4907-a4e9-47c7-bb63-54a3dc971a7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load the Dataset"
      ],
      "metadata": {
        "id": "Z7VRBzMasavE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/drive/MyDrive/Sem 1/Machine Learning/Assignment 2/dataset/demographics.csv\"\n",
        "\n",
        "print(\"Loading dataset...\")\n",
        "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
        "                'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
        "                'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
        "\n",
        "df = pd.read_csv(dataset_path, names=column_names, skipinitialspace=True)\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Replace '?' with NaN to identify missing values\n",
        "print(\"\\nReplacing '?' with NaN to identify missing values...\")\n",
        "df = df.replace('?', np.nan)\n",
        "\n",
        "print(\"\\nMissing values by column:\")\n",
        "missing_counts = df.isnull().sum()\n",
        "print(missing_counts[missing_counts > 0])\n",
        "print(f\"\\nTotal rows with missing values: {df.isnull().any(axis=1).sum()}\")\n",
        "\n",
        "print(\"\\nTarget variable distribution:\")\n",
        "print(df['income'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_x0_XlYscHo",
        "outputId": "6ee565ee-5a1e-447d-e98f-34725d31f090"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Loading dataset...\n",
            "Dataset shape: (32561, 15)\n",
            "\n",
            "First few rows:\n",
            "   age         workclass  fnlwgt  education  education-num  \\\n",
            "0   39         State-gov   77516  Bachelors             13   \n",
            "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
            "2   38           Private  215646    HS-grad              9   \n",
            "3   53           Private  234721       11th              7   \n",
            "4   28           Private  338409  Bachelors             13   \n",
            "\n",
            "       marital-status         occupation   relationship   race     sex  \\\n",
            "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
            "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
            "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
            "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
            "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
            "\n",
            "   capital-gain  capital-loss  hours-per-week native-country income  \n",
            "0          2174             0              40  United-States  <=50K  \n",
            "1             0             0              13  United-States  <=50K  \n",
            "2             0             0              40  United-States  <=50K  \n",
            "3             0             0              40  United-States  <=50K  \n",
            "4             0             0              40           Cuba  <=50K  \n",
            "\n",
            "Dataset info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32561 entries, 0 to 32560\n",
            "Data columns (total 15 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   age             32561 non-null  int64 \n",
            " 1   workclass       32561 non-null  object\n",
            " 2   fnlwgt          32561 non-null  int64 \n",
            " 3   education       32561 non-null  object\n",
            " 4   education-num   32561 non-null  int64 \n",
            " 5   marital-status  32561 non-null  object\n",
            " 6   occupation      32561 non-null  object\n",
            " 7   relationship    32561 non-null  object\n",
            " 8   race            32561 non-null  object\n",
            " 9   sex             32561 non-null  object\n",
            " 10  capital-gain    32561 non-null  int64 \n",
            " 11  capital-loss    32561 non-null  int64 \n",
            " 12  hours-per-week  32561 non-null  int64 \n",
            " 13  native-country  32561 non-null  object\n",
            " 14  income          32561 non-null  object\n",
            "dtypes: int64(6), object(9)\n",
            "memory usage: 3.7+ MB\n",
            "None\n",
            "\n",
            "Replacing '?' with NaN to identify missing values...\n",
            "\n",
            "Missing values by column:\n",
            "workclass         1836\n",
            "occupation        1843\n",
            "native-country     583\n",
            "dtype: int64\n",
            "\n",
            "Total rows with missing values: 2399\n",
            "\n",
            "Target variable distribution:\n",
            "income\n",
            "<=50K    24720\n",
            ">50K      7841\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Preprocessing\n",
        "\n",
        "This section handles:\n",
        "- Missing value treatment (replacing '?' with NaN and dropping rows)\n",
        "- Target variable encoding\n",
        "- Categorical variable encoding\n",
        "- Feature identification"
      ],
      "metadata": {
        "id": "Y0RCiSP4tqeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*80)\n",
        "print(\"DATA PREPROCESSING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Handle missing values - drop rows with missing values\n",
        "print(f\"\\nRows before dropping missing values: {len(df)}\")\n",
        "df = df.dropna()\n",
        "print(f\"Rows after dropping missing values: {len(df)}\")\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('income', axis=1)\n",
        "y = df['income']\n",
        "\n",
        "# Encode target variable\n",
        "print(\"\\nEncoding target variable...\")\n",
        "label_encoder_y = LabelEncoder()\n",
        "y = label_encoder_y.fit_transform(y)\n",
        "print(f\"Classes: {label_encoder_y.classes_}\")\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "\n",
        "print(f\"\\nCategorical columns: {categorical_cols}\")\n",
        "print(f\"Numerical columns: {numerical_cols}\")\n",
        "\n",
        "# Encode categorical variables\n",
        "print(\"\\nEncoding categorical variables...\")\n",
        "label_encoders = {}\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "print(\"Preprocessing complete!\")"
      ],
      "metadata": {
        "id": "zOE3lnpxtrqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d91f4271-4ed9-4782-c34d-c250be6b8617"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "DATA PREPROCESSING\n",
            "================================================================================\n",
            "\n",
            "Rows before dropping missing values: 32561\n",
            "Rows after dropping missing values: 30162\n",
            "\n",
            "Encoding target variable...\n",
            "Classes: ['<=50K' '>50K']\n",
            "\n",
            "Categorical columns: ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
            "Numerical columns: ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
            "\n",
            "Encoding categorical variables...\n",
            "Preprocessing complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Train-Test Split and Feature Scaling\n",
        "\n",
        "Split the data into training (80%) and testing (20%) sets, then standardize numerical features."
      ],
      "metadata": {
        "id": "yPiYIS37tyAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "print(\"Splitting data into train and test sets (80-20 split)...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"Training set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")\n",
        "\n",
        "# Standardize numerical features\n",
        "print(\"\\nStandardizing numerical features...\")\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "X_train_scaled[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
        "X_test_scaled[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
        "\n",
        "print(\"Data preparation complete!\")"
      ],
      "metadata": {
        "id": "2mchx0WWty9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce43dd19-e006-450b-954a-25967f208313"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting data into train and test sets (80-20 split)...\n",
            "Training set size: (24129, 14)\n",
            "Test set size: (6033, 14)\n",
            "\n",
            "Standardizing numerical features...\n",
            "Data preparation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Model Evaluation Function\n",
        "\n",
        "Define a reusable function to train and evaluate models with comprehensive metrics."
      ],
      "metadata": {
        "id": "PxgP2NhQt4Pi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate models\n",
        "def evaluate_model(model, model_name, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Train and evaluate a classification model\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"{model_name}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Train the model\n",
        "    print(f\"\\nTraining {model_name}...\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    y_pred_test = model.predict(X_test)\n",
        "\n",
        "    # Get prediction probabilities for AUC\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    else:\n",
        "        y_pred_proba = y_pred_test\n",
        "\n",
        "    # Calculate metrics\n",
        "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
        "    auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    precision = precision_score(y_test, y_pred_test, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred_test, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred_test, average='weighted')\n",
        "    mcc = matthews_corrcoef(y_test, y_pred_test)\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Display metrics in tabular format\n",
        "    print(\"\\nPerformance Metrics Table:\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"{'Metric':<25} {'Value':>20}\")\n",
        "    print(\"-\" * 50)\n",
        "    print(f\"{'Training Accuracy':<25} {train_accuracy:>20.4f}\")\n",
        "    print(f\"{'Test Accuracy':<25} {test_accuracy:>20.4f}\")\n",
        "    print(f\"{'AUC':<25} {auc:>20.4f}\")\n",
        "    print(f\"{'Precision':<25} {precision:>20.4f}\")\n",
        "    print(f\"{'Recall':<25} {recall:>20.4f}\")\n",
        "    print(f\"{'F1-Score':<25} {f1:>20.4f}\")\n",
        "    print(f\"{'MCC Score':<25} {mcc:>20.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred_test, target_names=label_encoder_y.classes_))\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    cm = confusion_matrix(y_test, y_pred_test)\n",
        "    cm_df = pd.DataFrame(cm,\n",
        "                         index=[f'Actual {label_encoder_y.classes_[0]}', f'Actual {label_encoder_y.classes_[1]}'],\n",
        "                         columns=[f'Predicted {label_encoder_y.classes_[0]}', f'Predicted {label_encoder_y.classes_[1]}'])\n",
        "    print(cm_df)\n",
        "\n",
        "    return {\n",
        "        'ML Model Name': model_name,\n",
        "        'Accuracy': test_accuracy,\n",
        "        'AUC': auc,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1': f1,\n",
        "        'MCC': mcc\n",
        "    }\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "print(\"Evaluation function defined successfully!\")"
      ],
      "metadata": {
        "id": "sWXw2GEPt5GA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ca1e7c-7a4e-4742-cafa-9603a23c1777"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation function defined successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Model 1: Logistic Regression\n",
        "\n",
        "Logistic Regression is a linear model for binary classification that uses the logistic function to predict probabilities."
      ],
      "metadata": {
        "id": "ellnmTFGt-kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_results = evaluate_model(lr_model, \"LOGISTIC REGRESSION\",\n",
        "                            X_train_scaled, X_test_scaled, y_train, y_test)\n",
        "results.append(lr_results)"
      ],
      "metadata": {
        "id": "c7O-h2Uyt_eG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7b5087-e233-49c0-d108-0bc6d84f78bc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LOGISTIC REGRESSION\n",
            "================================================================================\n",
            "\n",
            "Training LOGISTIC REGRESSION...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Performance Metrics Table:\n",
            "--------------------------------------------------\n",
            "Metric                                   Value\n",
            "--------------------------------------------------\n",
            "Training Accuracy                       0.8201\n",
            "Test Accuracy                           0.8177\n",
            "AUC                                     0.8500\n",
            "Precision                               0.8062\n",
            "Recall                                  0.8177\n",
            "F1-Score                                0.8019\n",
            "MCC Score                               0.4617\n",
            "--------------------------------------------------\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.84      0.94      0.89      4531\n",
            "        >50K       0.71      0.45      0.55      1502\n",
            "\n",
            "    accuracy                           0.82      6033\n",
            "   macro avg       0.78      0.69      0.72      6033\n",
            "weighted avg       0.81      0.82      0.80      6033\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "              Predicted <=50K  Predicted >50K\n",
            "Actual <=50K             4263             268\n",
            "Actual >50K               832             670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Model 2: Decision Tree Classifier\n",
        "\n",
        "Decision Tree is a tree-structured model that makes decisions by splitting data based on feature values."
      ],
      "metadata": {
        "id": "wMioaZbEuCeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_results = evaluate_model(dt_model, \"DECISION TREE CLASSIFIER\",\n",
        "                            X_train, X_test, y_train, y_test)\n",
        "results.append(dt_results)"
      ],
      "metadata": {
        "id": "u6PDhr9huG5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b5c4c59-16c8-4651-dfd2-62a5c00b1627"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "DECISION TREE CLASSIFIER\n",
            "================================================================================\n",
            "\n",
            "Training DECISION TREE CLASSIFIER...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Performance Metrics Table:\n",
            "--------------------------------------------------\n",
            "Metric                                   Value\n",
            "--------------------------------------------------\n",
            "Training Accuracy                       1.0000\n",
            "Test Accuracy                           0.8066\n",
            "AUC                                     0.7404\n",
            "Precision                               0.8062\n",
            "Recall                                  0.8066\n",
            "F1-Score                                0.8064\n",
            "MCC Score                               0.4817\n",
            "--------------------------------------------------\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.87      0.87      0.87      4531\n",
            "        >50K       0.61      0.61      0.61      1502\n",
            "\n",
            "    accuracy                           0.81      6033\n",
            "   macro avg       0.74      0.74      0.74      6033\n",
            "weighted avg       0.81      0.81      0.81      6033\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "              Predicted <=50K  Predicted >50K\n",
            "Actual <=50K             3952             579\n",
            "Actual >50K               588             914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Model 3: K-Nearest Neighbors Classifier\n",
        "\n",
        "KNN classifies samples based on the majority class of their k nearest neighbors in the feature space."
      ],
      "metadata": {
        "id": "AgK--Dw9uKb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_results = evaluate_model(knn_model, \"K-NEAREST NEIGHBORS CLASSIFIER\",\n",
        "                             X_train_scaled, X_test_scaled, y_train, y_test)\n",
        "results.append(knn_results)"
      ],
      "metadata": {
        "id": "rAFZI0VRuNgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff7b13c2-9217-44e8-f901-22b34e503df3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "K-NEAREST NEIGHBORS CLASSIFIER\n",
            "================================================================================\n",
            "\n",
            "Training K-NEAREST NEIGHBORS CLASSIFIER...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Performance Metrics Table:\n",
            "--------------------------------------------------\n",
            "Metric                                   Value\n",
            "--------------------------------------------------\n",
            "Training Accuracy                       0.8720\n",
            "Test Accuracy                           0.8253\n",
            "AUC                                     0.8433\n",
            "Precision                               0.8191\n",
            "Recall                                  0.8253\n",
            "F1-Score                                0.8212\n",
            "MCC Score                               0.5142\n",
            "--------------------------------------------------\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.87      0.90      0.89      4531\n",
            "        >50K       0.67      0.59      0.63      1502\n",
            "\n",
            "    accuracy                           0.83      6033\n",
            "   macro avg       0.77      0.75      0.76      6033\n",
            "weighted avg       0.82      0.83      0.82      6033\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "              Predicted <=50K  Predicted >50K\n",
            "Actual <=50K             4099             432\n",
            "Actual >50K               622             880\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Model 4: Naive Bayes Classifier (Gaussian)\n",
        "\n",
        "Gaussian Naive Bayes assumes features follow a normal distribution and applies Bayes' theorem with strong independence assumptions."
      ],
      "metadata": {
        "id": "s1PQfFaDuRJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_model = GaussianNB()\n",
        "nb_results = evaluate_model(nb_model, \"NAIVE BAYES CLASSIFIER (GAUSSIAN)\",\n",
        "                            X_train_scaled, X_test_scaled, y_train, y_test)\n",
        "results.append(nb_results)"
      ],
      "metadata": {
        "id": "DgL0rTSXuTt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816352a3-493b-4168-ea5b-bb53a5b427d9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "NAIVE BAYES CLASSIFIER (GAUSSIAN)\n",
            "================================================================================\n",
            "\n",
            "Training NAIVE BAYES CLASSIFIER (GAUSSIAN)...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Performance Metrics Table:\n",
            "--------------------------------------------------\n",
            "Metric                                   Value\n",
            "--------------------------------------------------\n",
            "Training Accuracy                       0.7960\n",
            "Test Accuracy                           0.7978\n",
            "AUC                                     0.8498\n",
            "Precision                               0.7830\n",
            "Recall                                  0.7978\n",
            "F1-Score                                0.7697\n",
            "MCC Score                               0.3798\n",
            "--------------------------------------------------\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.81      0.95      0.88      4531\n",
            "        >50K       0.70      0.33      0.45      1502\n",
            "\n",
            "    accuracy                           0.80      6033\n",
            "   macro avg       0.75      0.64      0.66      6033\n",
            "weighted avg       0.78      0.80      0.77      6033\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "              Predicted <=50K  Predicted >50K\n",
            "Actual <=50K             4317             214\n",
            "Actual >50K              1006             496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10. Model 5: Random Forest Classifier (Ensemble)\n",
        "\n",
        "Random Forest is an ensemble method that builds multiple decision trees and combines their predictions through voting."
      ],
      "metadata": {
        "id": "x5u6WCojuXLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_results = evaluate_model(rf_model, \"RANDOM FOREST CLASSIFIER\",\n",
        "                            X_train, X_test, y_train, y_test)\n",
        "results.append(rf_results)"
      ],
      "metadata": {
        "id": "o9cc3NmwuZh9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f1c3cad-c988-4310-e991-73a1ea99085d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "RANDOM FOREST CLASSIFIER\n",
            "================================================================================\n",
            "\n",
            "Training RANDOM FOREST CLASSIFIER...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Performance Metrics Table:\n",
            "--------------------------------------------------\n",
            "Metric                                   Value\n",
            "--------------------------------------------------\n",
            "Training Accuracy                       1.0000\n",
            "Test Accuracy                           0.8541\n",
            "AUC                                     0.9027\n",
            "Precision                               0.8489\n",
            "Recall                                  0.8541\n",
            "F1-Score                                0.8500\n",
            "MCC Score                               0.5927\n",
            "--------------------------------------------------\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.88      0.93      0.91      4531\n",
            "        >50K       0.74      0.63      0.68      1502\n",
            "\n",
            "    accuracy                           0.85      6033\n",
            "   macro avg       0.81      0.78      0.79      6033\n",
            "weighted avg       0.85      0.85      0.85      6033\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "              Predicted <=50K  Predicted >50K\n",
            "Actual <=50K             4203             328\n",
            "Actual >50K               552             950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11. Model 6: XGBoost Classifier (Ensemble)\n",
        "\n",
        "XGBoost is a gradient boosting ensemble method that builds trees sequentially, each correcting errors from previous trees."
      ],
      "metadata": {
        "id": "uMSj6tkQuciH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model = XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "xgb_results = evaluate_model(xgb_model, \"XGBOOST CLASSIFIER\",\n",
        "                             X_train, X_test, y_train, y_test)\n",
        "results.append(xgb_results)"
      ],
      "metadata": {
        "id": "_aVoL8F0ufCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89db662c-2afd-43b9-ef60-3cbf72cb785e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "XGBOOST CLASSIFIER\n",
            "================================================================================\n",
            "\n",
            "Training XGBOOST CLASSIFIER...\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Performance Metrics Table:\n",
            "--------------------------------------------------\n",
            "Metric                                   Value\n",
            "--------------------------------------------------\n",
            "Training Accuracy                       0.9113\n",
            "Test Accuracy                           0.8616\n",
            "AUC                                     0.9204\n",
            "Precision                               0.8567\n",
            "Recall                                  0.8616\n",
            "F1-Score                                0.8574\n",
            "MCC Score                               0.6131\n",
            "--------------------------------------------------\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <=50K       0.89      0.93      0.91      4531\n",
            "        >50K       0.76      0.64      0.70      1502\n",
            "\n",
            "    accuracy                           0.86      6033\n",
            "   macro avg       0.83      0.79      0.80      6033\n",
            "weighted avg       0.86      0.86      0.86      6033\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "              Predicted <=50K  Predicted >50K\n",
            "Actual <=50K             4232             299\n",
            "Actual >50K               536             966\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 12. Model Comparison Summary\n",
        "\n",
        "Compare all models based on their performance metrics to identify the best performer."
      ],
      "metadata": {
        "id": "AEiHuEZuuCRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY - MODEL COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Create results dataframe\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Display the table\n",
        "print(\"-\" * 120)\n",
        "print(f\"{'ML Model Name':<40} {'Accuracy':>10} {'AUC':>10} {'Precision':>10} {'Recall':>10} {'F1':>10} {'MCC':>10}\")\n",
        "print(\"-\" * 120)\n",
        "for _, row in results_df.iterrows():\n",
        "    print(f\"{row['ML Model Name']:<40} {row['Accuracy']:>10.4f} {row['AUC']:>10.4f} {row['Precision']:>10.4f} {row['Recall']:>10.4f} {row['F1']:>10.4f} {row['MCC']:>10.4f}\")\n",
        "print(\"-\" * 120)\n",
        "\n",
        "# Find best model based on test accuracy\n",
        "best_model_idx = results_df['Accuracy'].idxmax()\n",
        "best_model = results_df.loc[best_model_idx, 'ML Model Name']\n",
        "best_accuracy = results_df.loc[best_model_idx, 'Accuracy']\n",
        "best_auc = results_df.loc[best_model_idx, 'AUC']\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(f\"Best Model: {best_model}\")\n",
        "print(f\"Test Accuracy: {best_accuracy:.4f}\")\n",
        "print(f\"AUC Score: {best_auc:.4f}\")\n",
        "print(f\"{'='*80}\")"
      ],
      "metadata": {
        "id": "da8XcReIulre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3731ffbd-7139-4705-9e35-739870102b5f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY - MODEL COMPARISON\n",
            "================================================================================\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "ML Model Name                              Accuracy        AUC  Precision     Recall         F1        MCC\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "LOGISTIC REGRESSION                          0.8177     0.8500     0.8062     0.8177     0.8019     0.4617\n",
            "DECISION TREE CLASSIFIER                     0.8066     0.7404     0.8062     0.8066     0.8064     0.4817\n",
            "K-NEAREST NEIGHBORS CLASSIFIER               0.8253     0.8433     0.8191     0.8253     0.8212     0.5142\n",
            "NAIVE BAYES CLASSIFIER (GAUSSIAN)            0.7978     0.8498     0.7830     0.7978     0.7697     0.3798\n",
            "RANDOM FOREST CLASSIFIER                     0.8541     0.9027     0.8489     0.8541     0.8500     0.5927\n",
            "XGBOOST CLASSIFIER                           0.8616     0.9204     0.8567     0.8616     0.8574     0.6131\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "\n",
            "================================================================================\n",
            "Best Model: XGBOOST CLASSIFIER\n",
            "Test Accuracy: 0.8616\n",
            "AUC Score: 0.9204\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 13. Model Performance Observations\n",
        "\n",
        "Detailed observations on the performance of each model on the Demographics dataset."
      ],
      "metadata": {
        "id": "dE3SI8DKuo2n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*80)\n",
        "print(\"MODEL PERFORMANCE OBSERVATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Sort models by accuracy for better comparison\n",
        "results_sorted = results_df.sort_values('Accuracy', ascending=False)\n",
        "\n",
        "print(\"\\n1. OVERALL PERFORMANCE RANKING (by Accuracy):\")\n",
        "print(\"-\" * 80)\n",
        "for idx, (i, row) in enumerate(results_sorted.iterrows(), 1):\n",
        "    print(f\"{idx}. {row['ML Model Name']}: {row['Accuracy']:.4f}\")\n",
        "\n",
        "print(\"\\n2. DETAILED OBSERVATIONS:\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "for _, row in results_df.iterrows():\n",
        "    model_name = row['ML Model Name']\n",
        "    accuracy = row['Accuracy']\n",
        "    auc = row['AUC']\n",
        "    precision = row['Precision']\n",
        "    recall = row['Recall']\n",
        "    f1 = row['F1']\n",
        "    mcc = row['MCC']\n",
        "\n",
        "    print(f\"\\n{model_name}:\")\n",
        "\n",
        "    # Performance level\n",
        "    if accuracy >= 0.85:\n",
        "        print(f\"  ✓ Excellent performance with {accuracy:.2%} accuracy\")\n",
        "    elif accuracy >= 0.80:\n",
        "        print(f\"  ✓ Good performance with {accuracy:.2%} accuracy\")\n",
        "    elif accuracy >= 0.75:\n",
        "        print(f\"  ○ Moderate performance with {accuracy:.2%} accuracy\")\n",
        "    else:\n",
        "        print(f\"  ✗ Lower performance with {accuracy:.2%} accuracy\")\n",
        "\n",
        "    # AUC interpretation\n",
        "    if auc >= 0.90:\n",
        "        print(f\"  ✓ Excellent discrimination capability (AUC: {auc:.4f})\")\n",
        "    elif auc >= 0.80:\n",
        "        print(f\"  ✓ Good discrimination capability (AUC: {auc:.4f})\")\n",
        "    else:\n",
        "        print(f\"  ○ Moderate discrimination capability (AUC: {auc:.4f})\")\n",
        "\n",
        "    # Precision-Recall balance\n",
        "    if abs(precision - recall) < 0.02:\n",
        "        print(f\"  ✓ Well-balanced precision ({precision:.4f}) and recall ({recall:.4f})\")\n",
        "    elif precision > recall:\n",
        "        print(f\"  ○ Higher precision ({precision:.4f}) than recall ({recall:.4f}) - fewer false positives\")\n",
        "    else:\n",
        "        print(f\"  ○ Higher recall ({recall:.4f}) than precision ({precision:.4f}) - fewer false negatives\")\n",
        "\n",
        "    # F1 Score\n",
        "    print(f\"  • F1-Score: {f1:.4f} - Overall balance between precision and recall\")\n",
        "\n",
        "    # MCC interpretation\n",
        "    if mcc >= 0.50:\n",
        "        print(f\"  ✓ Strong correlation (MCC: {mcc:.4f})\")\n",
        "    elif mcc >= 0.30:\n",
        "        print(f\"  ○ Moderate correlation (MCC: {mcc:.4f})\")\n",
        "    else:\n",
        "        print(f\"  ✗ Weak correlation (MCC: {mcc:.4f})\")\n",
        "\n",
        "print(\"\\n3. KEY INSIGHTS:\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Best overall model\n",
        "best_model_name = results_sorted.iloc[0]['ML Model Name']\n",
        "best_accuracy = results_sorted.iloc[0]['Accuracy']\n",
        "best_f1 = results_sorted.iloc[0]['F1']\n",
        "\n",
        "print(f\"\\n• Best Overall Model: {best_model_name}\")\n",
        "print(f\"  - Achieved highest accuracy of {best_accuracy:.2%}\")\n",
        "print(f\"  - F1-Score: {best_f1:.4f}\")\n",
        "\n",
        "# Best AUC\n",
        "best_auc_idx = results_df['AUC'].idxmax()\n",
        "best_auc_model = results_df.loc[best_auc_idx, 'ML Model Name']\n",
        "best_auc_score = results_df.loc[best_auc_idx, 'AUC']\n",
        "print(f\"\\n• Best AUC Score: {best_auc_model} ({best_auc_score:.4f})\")\n",
        "\n",
        "# Best MCC\n",
        "best_mcc_idx = results_df['MCC'].idxmax()\n",
        "best_mcc_model = results_df.loc[best_mcc_idx, 'ML Model Name']\n",
        "best_mcc_score = results_df.loc[best_mcc_idx, 'MCC']\n",
        "print(f\"\\n• Best MCC Score: {best_mcc_model} ({best_mcc_score:.4f})\")\n",
        "\n",
        "# Ensemble vs Traditional comparison\n",
        "ensemble_models = results_df[results_df['ML Model Name'].str.contains('FOREST|XGBOOST')]\n",
        "traditional_models = results_df[~results_df['ML Model Name'].str.contains('FOREST|XGBOOST')]\n",
        "\n",
        "if len(ensemble_models) > 0 and len(traditional_models) > 0:\n",
        "    avg_ensemble_acc = ensemble_models['Accuracy'].mean()\n",
        "    avg_traditional_acc = traditional_models['Accuracy'].mean()\n",
        "    print(f\"\\n• Ensemble Models Average Accuracy: {avg_ensemble_acc:.2%}\")\n",
        "    print(f\"• Traditional Models Average Accuracy: {avg_traditional_acc:.2%}\")\n",
        "\n",
        "    if avg_ensemble_acc > avg_traditional_acc:\n",
        "        improvement = ((avg_ensemble_acc - avg_traditional_acc) / avg_traditional_acc) * 100\n",
        "        print(f\"  → Ensemble models outperform traditional models by {improvement:.1f}%\")\n",
        "\n",
        "# Worst performing model\n",
        "worst_model_name = results_sorted.iloc[-1]['ML Model Name']\n",
        "worst_accuracy = results_sorted.iloc[-1]['Accuracy']\n",
        "print(f\"\\n• Lowest Performing Model: {worst_model_name} ({worst_accuracy:.2%})\")\n",
        "\n",
        "print(\"\\n4. RECOMMENDATIONS:\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"\\n• For deployment: Use {best_model_name} for best overall performance\")\n",
        "print(f\"• For interpretability: Consider DECISION TREE or LOGISTIC REGRESSION\")\n",
        "print(f\"• For handling imbalanced data: Consider models with high MCC scores\")\n",
        "if best_auc_score >= 0.85:\n",
        "    print(f\"• The {best_auc_model} shows excellent ability to distinguish between classes\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)"
      ],
      "metadata": {
        "id": "_dyWrjnxus3M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "624ab1f3-af7f-4a90-fc57-338336757416"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "MODEL PERFORMANCE OBSERVATIONS\n",
            "================================================================================\n",
            "\n",
            "1. OVERALL PERFORMANCE RANKING (by Accuracy):\n",
            "--------------------------------------------------------------------------------\n",
            "1. XGBOOST CLASSIFIER: 0.8616\n",
            "2. RANDOM FOREST CLASSIFIER: 0.8541\n",
            "3. K-NEAREST NEIGHBORS CLASSIFIER: 0.8253\n",
            "4. LOGISTIC REGRESSION: 0.8177\n",
            "5. DECISION TREE CLASSIFIER: 0.8066\n",
            "6. NAIVE BAYES CLASSIFIER (GAUSSIAN): 0.7978\n",
            "\n",
            "2. DETAILED OBSERVATIONS:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "LOGISTIC REGRESSION:\n",
            "  ✓ Good performance with 81.77% accuracy\n",
            "  ✓ Good discrimination capability (AUC: 0.8500)\n",
            "  ✓ Well-balanced precision (0.8062) and recall (0.8177)\n",
            "  • F1-Score: 0.8019 - Overall balance between precision and recall\n",
            "  ○ Moderate correlation (MCC: 0.4617)\n",
            "\n",
            "DECISION TREE CLASSIFIER:\n",
            "  ✓ Good performance with 80.66% accuracy\n",
            "  ○ Moderate discrimination capability (AUC: 0.7404)\n",
            "  ✓ Well-balanced precision (0.8062) and recall (0.8066)\n",
            "  • F1-Score: 0.8064 - Overall balance between precision and recall\n",
            "  ○ Moderate correlation (MCC: 0.4817)\n",
            "\n",
            "K-NEAREST NEIGHBORS CLASSIFIER:\n",
            "  ✓ Good performance with 82.53% accuracy\n",
            "  ✓ Good discrimination capability (AUC: 0.8433)\n",
            "  ✓ Well-balanced precision (0.8191) and recall (0.8253)\n",
            "  • F1-Score: 0.8212 - Overall balance between precision and recall\n",
            "  ✓ Strong correlation (MCC: 0.5142)\n",
            "\n",
            "NAIVE BAYES CLASSIFIER (GAUSSIAN):\n",
            "  ○ Moderate performance with 79.78% accuracy\n",
            "  ✓ Good discrimination capability (AUC: 0.8498)\n",
            "  ✓ Well-balanced precision (0.7830) and recall (0.7978)\n",
            "  • F1-Score: 0.7697 - Overall balance between precision and recall\n",
            "  ○ Moderate correlation (MCC: 0.3798)\n",
            "\n",
            "RANDOM FOREST CLASSIFIER:\n",
            "  ✓ Excellent performance with 85.41% accuracy\n",
            "  ✓ Excellent discrimination capability (AUC: 0.9027)\n",
            "  ✓ Well-balanced precision (0.8489) and recall (0.8541)\n",
            "  • F1-Score: 0.8500 - Overall balance between precision and recall\n",
            "  ✓ Strong correlation (MCC: 0.5927)\n",
            "\n",
            "XGBOOST CLASSIFIER:\n",
            "  ✓ Excellent performance with 86.16% accuracy\n",
            "  ✓ Excellent discrimination capability (AUC: 0.9204)\n",
            "  ✓ Well-balanced precision (0.8567) and recall (0.8616)\n",
            "  • F1-Score: 0.8574 - Overall balance between precision and recall\n",
            "  ✓ Strong correlation (MCC: 0.6131)\n",
            "\n",
            "3. KEY INSIGHTS:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "• Best Overall Model: XGBOOST CLASSIFIER\n",
            "  - Achieved highest accuracy of 86.16%\n",
            "  - F1-Score: 0.8574\n",
            "\n",
            "• Best AUC Score: XGBOOST CLASSIFIER (0.9204)\n",
            "\n",
            "• Best MCC Score: XGBOOST CLASSIFIER (0.6131)\n",
            "\n",
            "• Ensemble Models Average Accuracy: 85.79%\n",
            "• Traditional Models Average Accuracy: 81.18%\n",
            "  → Ensemble models outperform traditional models by 5.7%\n",
            "\n",
            "• Lowest Performing Model: NAIVE BAYES CLASSIFIER (GAUSSIAN) (79.78%)\n",
            "\n",
            "4. RECOMMENDATIONS:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "• For deployment: Use XGBOOST CLASSIFIER for best overall performance\n",
            "• For interpretability: Consider DECISION TREE or LOGISTIC REGRESSION\n",
            "• For handling imbalanced data: Consider models with high MCC scores\n",
            "• The XGBOOST CLASSIFIER shows excellent ability to distinguish between classes\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e52BfSYhuwVt"
      }
    }
  ]
}